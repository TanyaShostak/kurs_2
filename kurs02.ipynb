{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-vrcHps7HYcl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database = input()\n",
        "with open(database, newline='') as source:\n",
        "    reader = csv.DictReader(source)\n",
        "    with open('export.csv', mode='w', encoding='utf-8-sig', newline='') as destination:\n",
        "\n",
        "        writer = csv.DictWriter(destination, dialect=csv.unix_dialect, fieldnames=reader.fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(\n",
        "            filter(lambda x: 'V' in x.get('Name') or 'X' in x.get('Name'), reader)\n",
        "        )"
      ],
      "metadata": {
        "id": "kLw2sSu0lBNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8463d5-9071-471a-eceb-c6702bc8a8f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "database.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('export.csv', newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    k = 0\n",
        "   # for x in reader:\n",
        "    #    print(x['Name'])"
      ],
      "metadata": {
        "id": "tsSEy-Fpn8mi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(diction, name, number):\n",
        "    sent = \"\"\n",
        "    for i in str(diction[name][number]):\n",
        "        if i not in \"qwertyuioplkjhgfdsazxcvbnmQWERTYUIOPLKJHGFDSAZXCVBNM[]\":\n",
        "            sent = sent + i\n",
        "    return(sent)"
      ],
      "metadata": {
        "id": "IMm7V1PrTkKe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff = pd.read_csv('export.csv', delimiter=',')\n",
        "slov = {}\n",
        "slov_synt = {}\n",
        "for i in range(len(dff)):\n",
        "    slov[clean(dff, \"Example 1\", i)] = dff[\"SemType1\"][i]\n",
        "    slov[clean(dff, \"Example 2\", i)] = dff[\"SemType1\"][i]\n",
        "    slov[clean(dff, \"Example 3\", i)] = dff[\"SemType1\"][i]\n",
        "    slov[clean(dff, \"Example 4\", i)] = dff[\"SemType1\"][i]\n",
        "    slov[clean(dff, \"Example 5\", i)] = dff[\"SemType1\"][i]\n",
        "    slov_synt[clean(dff, \"Example 1\", i)] = dff['Synt. type of construction'][i]\n",
        "    slov_synt[clean(dff, \"Example 2\", i)] = dff['Synt. type of construction'][i]\n",
        "    slov_synt[clean(dff, \"Example 3\", i)] = dff['Synt. type of construction'][i]\n",
        "    slov_synt[clean(dff, \"Example 4\", i)] = dff['Synt. type of construction'][i]\n",
        "    slov_synt[clean(dff, \"Example 5\", i)] = dff['Synt. type of construction'][i]"
      ],
      "metadata": {
        "id": "RdJ-b6OjzIO8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(slov. items ()), columns = ['Example', 'SemType'])"
      ],
      "metadata": {
        "id": "CMoFrV-qS20F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_test, y_train, y_test = train_test_split(df['Example'], df['SemType'], test_size=0.4, random_state=0)"
      ],
      "metadata": {
        "id": "Iv5eR0QcSQPQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('SemType1.csv', 'w', newline='') as csvfile:\n",
        "    filewriter = csv.writer(csvfile, delimiter=',')\n",
        "    for i in data_train:\n",
        "        filewriter.writerow(['tr', i, slov[i]])\n",
        "    for i in data_test:\n",
        "        filewriter.writerow(['te', i, slov[i]])\n",
        "    "
      ],
      "metadata": {
        "id": "UUbfpJzOWox9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('SyntType.csv', 'w', newline='') as csvfile:\n",
        "    filewriter = csv.writer(csvfile, delimiter=',')\n",
        "    for i in data_train:\n",
        "        filewriter.writerow(['tr', i, slov_synt[i]])\n",
        "    for i in data_test:\n",
        "        filewriter.writerow(['te', i, slov_synt[i]])"
      ],
      "metadata": {
        "id": "JE7zyzKLEHiQ"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}